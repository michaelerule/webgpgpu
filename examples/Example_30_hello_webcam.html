<!DOCTYPE html>
<html>
<script id="vertices" type="x-shader/x-vertex">
attribute vec2 a_position;
void main() {gl_Position = vec4(a_position,0,1);}
</script>
<script id="fragment" type="x-shader/x-fragment">
precision mediump float;
uniform sampler2D data;
void main() {
    vec3 color = vec3(1.0)-texture2D(data,gl_FragCoord.xy/vec2(512,512)).zyx;
    gl_FragColor = vec4(color.xyz,1.0);
}
</script>



<script>
$ = function(id) { return document.getElementById(id); }

// This is the main script that will run when the website loads
function main()
{
    //////////////////////////////////////////////////////////////////
    // Set up WebGL canvas
    // Retrieve a handle to the canvas element
    var canvas = $("maincanvas");
    // Try to create a WebGL context on the canvas, abort if it fails
    var gl = canvas.getContext("webgl")
          || canvas.getContext("experimental-webgl");
    if (!gl) { alert("No Gl?"); return; }
    // Set clear color and then clear the canvas
    gl.clearColor(0.5, 0.7, 0.6, 1.0);
    gl.clear(gl.COLOR_BUFFER_BIT);
    // There are two dimensions we need to worry about
    // The canvas itself has a "fictional" dimension which is scaled
    // to the screen dimensions (you can do automatic up or
    // downsampling by setting this higher or lower than the actual
    // on-screen size). The webgl context also has its own ideas
    // about the size of the viewport that must be brought match.
    canvas.width=canvas.height=512;
    gl.viewport(0, 0, canvas.width, canvas.height);

    //////////////////////////////////////////////////////////////////
    // We have to manually walk through the compiliation and linking
    // steps for the vertex (polygons) and fragment (pixel) shader
    // programs; Each program must be created, initialized, compiled,
    // bound to our gl context, and the whole lot must then be linked
    // and put to use.
    var program  = gl.createProgram();
    function loadShader(shaderSource) {
        var shader = shaderSource.type=="x-shader/x-fragment"
            ? gl.createShader(gl.FRAGMENT_SHADER)
            : gl.createShader(gl.VERTEX_SHADER);
        gl.shaderSource (shader,shaderSource.text);
        gl.compileShader(shader);
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
            alert(gl.getShaderInfoLog(shader));
            return null;
        }
        gl.attachShader(program, shader);
    }
    loadShader($("vertices"));
    loadShader($("fragment"));
    gl.linkProgram(program);
    gl.useProgram (program);

    //gl.bindFramebuffer(gl.FRAMEBUFFER,null);//framebuffer||null);

    //////////////////////////////////////////////////////////////////
    // Make a quadrilateral that will serve as the drawing surface
    // Remember that WebGL descends from OpenGL for drawing 3D scenes
    // Think of this as a minimal 3D model serving as a "screen"
    var buffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
    gl.bufferData(gl.ARRAY_BUFFER,new Float32Array([-1,-1,1,-1,-1,1,-1,1,1,-1,1,1]),gl.STATIC_DRAW);
    // We also need to manually pass arguments to the shader
    positionLocation = gl.getAttribLocation(program, "a_position");
    gl.enableVertexAttribArray(positionLocation);
    gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);
    // Finally, render scene
    //gl.drawArrays(gl.TRIANGLES, 0, 6);
    
    
        
    
    
    //////////////////////////////////////////////////////////////////
    // WEBCAM CONTROL
    // Adapted from p5js.org/examples/3d-shader-using-webcam.html
    let camera = $("camera");
    // Ask the user for permission to use their webcam
    navigator.mediaDevices.getUserMedia({video:1,audio:0}).then(
        // fulfilled method resolves to a MediaStream object,
        // bind this MediaStream to the camera page element.
        (stream)=>{ try {
            if ('srcObject' in camera) camera.srcObject = stream;
            else camera.src = window.URL.createObjectURL(stream);
        } catch (err) {camera.src = stream;}}, 
        // Rejected method: print to console
        console.log 
    );
    // Start capturing video stream
    camera.play();   
    
    //////////////////////////////////////////////////////////////////
    // Create a texture object 
    var texture = gl.createTexture();
    // Bind the texture the target (TEXTURE_2D) of the active texture unit.
    gl.bindTexture(gl.TEXTURE_2D, texture);
    // Flip the image's Y axis to match the WebGL texture coordinate space.
    gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
    // Set the parameters so we can render any size image.        
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE); 
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
    // Upload the resized canvas image into the texture.
    // Note: a canvas is used here but can be replaced by an image object. 
    //gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);
    // assign a 1Ã—1 empty texture initially, because data is not yet ready,
    // so that no errors occur in gl console!
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, new Uint8Array([128,0,0,255]));
    // Test draw 
    gl.drawArrays(gl.TRIANGLES, 0, 6);   
         

     
    //////////////////////////////////////////////////////////////////     
    // Stash
    var param = gl.getActiveUniform(program,0); // data bind point
    param.name      = param.name;
    param.type      = param.type;
    param.size      = param.size;
    param.typename  = glConstant(gl,param.type)
    param.shortname = param.name.split('[')[0];
    param.location  = gl.getUniformLocation(program,param.shortname);
                  
    // isSrcMediaElement this.src.elt;
    // Start an animation loop
    function animate(){
        /*
        // passing cam as a texture
        theShader.setUniform('tex0', cam);
        
        getTexture(data);
        
        // case gl.SAMPLER_2D:
        gl.activeTexture(gl.TEXTURE0 + uniform.samplerIndex);
        uniform.texture = data instanceof _main.default.Texture ? data : this._renderer.getTexture(data);
        gl.uniform1i(location, uniform.samplerIndex);

        src = data;
        var tex = new _main.default.Texture(this, data);
        */

        //this.bindTexture();
        //gl.texImage2D(this.glTarget, 0, this.glFormat, this.glFormat, this.glDataType, textureData);
        //gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);
        
        gl.bindTexture(gl.TEXTURE_2D, texture);
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, camera);
    
        // Send to WebGL canvas
        //var param = getParameter(gl, program, "data");
        
        //param.set(texture,0);    
        gl.useProgram(program);
        gl.uniform1i(param.location,0);
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D,texture);
        gl.drawArrays(gl.TRIANGLES, 0, 6);   
            
        setTimeout(animate,50); // or requestAnimationFrame(animate);
    }
    animate();
    
    
    /*
    // Some browsers partially implement mediaDevices. We can't just assign an object
    // with getUserMedia as it would overwrite existing properties.
    // Here, we will just add the getUserMedia property if it's missing.
    if (navigator.mediaDevices.getUserMedia === undefined) {
      navigator.mediaDevices.getUserMedia = function (constraints) {
        // First get ahold of the legacy getUserMedia, if present
        var getUserMedia = navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
        // Some browsers just don't implement it - return a rejected promise with an error
        // to keep a consistent interface
        if (!getUserMedia) {
          return Promise.reject(new Error('getUserMedia is not implemented in this browser'));
        }            // Otherwise, wrap the call to the old navigator.getUserMedia with a Promise
        return new Promise(function (resolve, reject) {
          getUserMedia.call(navigator, constraints, resolve, reject);
        });
      };
      */
    console.log('done');
}
function glConstant(gl,i) {
    if (!gl.hasOwnProperty('__GL_CONSTANTS_MAP__')) {
        gl.__GL_CONSTANTS_MAP__ = {};
        for (k in gl) gl.__GL_CONSTANTS_MAP__[gl[k]] = k;
    }
    return gl.__GL_CONSTANTS_MAP__[i];
}
</script>
<body onload="javascript:main()">
<canvas id='maincanvas' style="width:512px;height:512px;"></canvas>
<!-- Video capture element: (add " display:none;" to style to hide this) -->
<video id='camera' width="512" height="512" visible="False" style="width: 512px; height: 512px;" controls="true" playsinline="" crossorigin="anonymous"></video>
</body>
</html>
